{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Torch Find Peaks Documentation","text":"<p>Welcome to the documentation for the <code>torch-find-peaks</code> library.</p>"},{"location":"#overview","title":"Overview","text":"<p>The <code>torch-find-peaks</code> library provides utilities for detecting and refining peaks in 2D and 3D data using PyTorch. It includes methods for peak detection, Gaussian fitting, and more.</p>"},{"location":"#installation","title":"Installation","text":"<p>To install the library, use:</p> <pre><code>pip install torch-find-peaks\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>Here are some of the key functionalities provided by the library:</p> <ul> <li>Peak Detection: Detect peaks in 2D images or 3D volumes.</li> <li>Gaussian Fitting: Fit 2D or 3D Gaussian functions to refine peak positions.</li> </ul>"},{"location":"#api-reference","title":"API Reference","text":""},{"location":"#torch_find_peaksfind_peaks","title":"<code>torch_find_peaks.find_peaks</code>","text":""},{"location":"#torch_find_peaks.find_peaks.find_peaks_2d","title":"<code>find_peaks_2d(image, min_distance=1, threshold_abs=0.0, exclude_border=0, return_as='torch')</code>","text":"<p>Find local peaks in a 2D image.</p> <p>Accepts various input types (torch.Tensor, numpy.ndarray) and attempts to convert them to torch.Tensor before processing.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Any</code> <p>A 2D tensor-like object (e.g., torch.Tensor, numpy.ndarray) representing the input image.</p> required <code>min_distance</code> <code>int</code> <p>Minimum distance between peaks. Default is 1.</p> <code>1</code> <code>threshold_abs</code> <code>float</code> <p>Minimum intensity value for a peak to be considered. Default is 0.0.</p> <code>0.0</code> <code>exclude_border</code> <code>int</code> <p>Width of the border to exclude from peak detection. Default is 0.</p> <code>0</code> <code>return_as</code> <code>str</code> <p>The format of the output. Default is \"torch\". Other options are \"numpy\" and \"dataframe\".</p> <code>'torch'</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (N, 2), where N is the number of peaks, and each row contains the (Y, X) coordinates of a peak.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the input image cannot be converted to a torch.Tensor.</p> <code>ValueError</code> <p>If the input image is not 2-dimensional after conversion.</p> Source code in <code>src/torch_find_peaks/find_peaks.py</code> <pre><code>def find_peaks_2d(\n        image: Union[torch.Tensor, np.ndarray], \n        min_distance: int = 1,\n        threshold_abs: float = 0.0,\n        exclude_border: int = 0,\n        return_as: Literal[\"torch\",\"numpy\",\"dataframe\"] = \"torch\",\n) -&gt; torch.Tensor:\n    \"\"\"\n    Find local peaks in a 2D image.\n\n    Accepts various input types (torch.Tensor, numpy.ndarray) and attempts\n    to convert them to torch.Tensor before processing.\n\n    Parameters\n    ----------\n    image : Any\n        A 2D tensor-like object (e.g., torch.Tensor, numpy.ndarray)\n        representing the input image.\n    min_distance : int, optional\n        Minimum distance between peaks. Default is 1.\n    threshold_abs : float, optional\n        Minimum intensity value for a peak to be considered. Default is 0.0.\n    exclude_border : int, optional\n        Width of the border to exclude from peak detection. Default is 0.\n    return_as : str, optional\n        The format of the output. Default is \"torch\".\n        Other options are \"numpy\" and \"dataframe\".\n\n    Returns\n    -------\n    torch.Tensor\n        A tensor of shape (N, 2), where N is the number of peaks, and each row\n        contains the (Y, X) coordinates of a peak.\n\n    Raises\n    ------\n    TypeError\n        If the input image cannot be converted to a torch.Tensor.\n    ValueError\n        If the input image is not 2-dimensional after conversion.\n    \"\"\"\n    if isinstance(image, torch.Tensor):\n        image_tensor = image\n    elif isinstance(image, np.ndarray):\n        image_tensor = torch.from_numpy(image)\n    # Add checks for pandas/polars DataFrames/Series here if needed\n    # elif pd and isinstance(image, pd.DataFrame):\n    #     image_tensor = torch.from_numpy(image.values)\n    # elif pl and isinstance(image, pl.DataFrame):\n    #     image_tensor = torch.from_numpy(image.to_numpy())\n    else:\n        try:\n            # Attempt a general conversion for other array-like objects\n            image_tensor = torch.as_tensor(image)\n        except Exception as e:\n            raise TypeError(\n                f\"Input type {type(image)} not supported or conversion failed: {e}\"\n            )\n\n    if image_tensor.ndim != 2:\n        raise ValueError(\n            f\"Input image must be 2-dimensional, but got {image_tensor.ndim} dimensions.\"\n        )\n\n    found_peaks, heights = _find_peaks_2d_torch(\n        image=image_tensor,\n        min_distance=min_distance,\n        threshold_abs=threshold_abs,\n        exclude_border=exclude_border,\n    )\n\n    if return_as == \"torch\":\n        return found_peaks, heights\n    elif return_as == \"numpy\":\n        return found_peaks.numpy(), heights.numpy()\n    elif return_as == \"dataframe\":\n        # Use einops.pack to properly handle tensors with different dimensions\n        # First tensor has shape [N, 2], second has shape [N]\n        # We're packing them along the second dimension (dim=1)\n        packed, _ = einops.pack([found_peaks, heights], 'n *')\n        return pd.DataFrame(packed.cpu(), columns=[\"y\", \"x\", \"height\"])\n    else:\n        raise ValueError(f\"Invalid return_as value: {return_as}\")\n</code></pre>"},{"location":"#torch_find_peaks.find_peaks.find_peaks_3d","title":"<code>find_peaks_3d(volume, min_distance=1, threshold_abs=0.0, exclude_border=0, return_as='torch')</code>","text":"<p>Find local peaks in a 3D volume.</p> <p>Accepts various input types (torch.Tensor, numpy.ndarray) and attempts to convert them to torch.Tensor before processing.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>Any</code> <p>A 3D tensor-like object (e.g., torch.Tensor, numpy.ndarray) representing the input volume.</p> required <code>min_distance</code> <code>int</code> <p>Minimum distance between peaks. Default is 1.</p> <code>1</code> <code>threshold_abs</code> <code>float</code> <p>Minimum intensity value for a peak to be considered. Default is 0.0.</p> <code>0.0</code> <code>exclude_border</code> <code>int</code> <p>Width of the border to exclude from peak detection. Default is 0.</p> <code>0</code> <code>return_as</code> <code>str</code> <p>The format of the output. Default is \"torch\". Other options are \"numpy\" and \"dataframe\".</p> <code>'torch'</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (N, 3), where N is the number of peaks, and each row contains the (Z, Y, X) coordinates of a peak.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the input volume cannot be converted to a torch.Tensor.</p> <code>ValueError</code> <p>If the input volume is not 3-dimensional after conversion.</p> Source code in <code>src/torch_find_peaks/find_peaks.py</code> <pre><code>def find_peaks_3d(\n        volume: Union[torch.Tensor, np.ndarray], \n        min_distance: int = 1,\n        threshold_abs: float = 0.0,\n        exclude_border: int = 0,\n        return_as: Literal[\"torch\",\"numpy\",\"dataframe\"] = \"torch\",\n) -&gt; torch.Tensor:\n    \"\"\"\n    Find local peaks in a 3D volume.\n\n    Accepts various input types (torch.Tensor, numpy.ndarray) and attempts\n    to convert them to torch.Tensor before processing.\n\n    Parameters\n    ----------\n    volume : Any\n        A 3D tensor-like object (e.g., torch.Tensor, numpy.ndarray)\n        representing the input volume.\n    min_distance : int, optional\n        Minimum distance between peaks. Default is 1.\n    threshold_abs : float, optional\n        Minimum intensity value for a peak to be considered. Default is 0.0.\n    exclude_border : int, optional\n        Width of the border to exclude from peak detection. Default is 0.\n    return_as : str, optional\n        The format of the output. Default is \"torch\".\n        Other options are \"numpy\" and \"dataframe\".\n\n    Returns\n    -------\n    torch.Tensor\n        A tensor of shape (N, 3), where N is the number of peaks, and each row\n        contains the (Z, Y, X) coordinates of a peak.\n\n    Raises\n    ------\n    TypeError\n        If the input volume cannot be converted to a torch.Tensor.\n    ValueError\n        If the input volume is not 3-dimensional after conversion.\n    \"\"\"\n    if isinstance(volume, torch.Tensor):\n        volume_tensor = volume\n    elif isinstance(volume, np.ndarray):\n        volume_tensor = torch.from_numpy(volume)\n    # Add checks for pandas/polars DataFrames/Series here if needed\n    else:\n        try:\n            # Attempt a general conversion for other array-like objects\n            volume_tensor = torch.as_tensor(volume)\n        except Exception as e:\n            raise TypeError(\n                f\"Input type {type(volume)} not supported or conversion failed: {e}\"\n            )\n\n    if volume_tensor.ndim != 3:\n        raise ValueError(\n            f\"Input volume must be 3-dimensional, but got {volume_tensor.ndim} dimensions.\"\n        )\n\n    found_peaks, heights = _find_peaks_3d_torch(\n        volume=volume_tensor,\n        min_distance=min_distance,\n        threshold_abs=threshold_abs,\n        exclude_border=exclude_border,\n    )\n\n    if return_as == \"torch\":\n        return found_peaks, heights\n    elif return_as == \"numpy\":\n        return found_peaks.cpu().numpy(), heights.cpu().numpy()\n    elif return_as == \"dataframe\":\n        # Use einops.pack to properly handle tensors with different dimensions\n        # First tensor has shape [N, 3], second has shape [N]\n        # We're packing them along the second dimension (dim=1)\n        packed, _ = einops.pack([found_peaks, heights], 'n *')\n        return pd.DataFrame(packed.cpu(), columns=[\"z\", \"y\", \"x\", \"height\"])\n    else:\n        raise ValueError(f\"Invalid return_as value: {return_as}\")\n</code></pre>"},{"location":"#torch_find_peaksrefine_peaks","title":"<code>torch_find_peaks.refine_peaks</code>","text":""},{"location":"#torch_find_peaks.refine_peaks.refine_peaks_2d","title":"<code>refine_peaks_2d(image, peak_coords, boxsize, max_iterations=1000, learning_rate=0.01, tolerance=1e-06, amplitude=1.0, sigma_x=1.0, sigma_y=1.0, return_as='torch')</code>","text":"<p>Refine the positions of peaks in a 2D image by fitting 2D Gaussian functions.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>Any</code> <p>A 2D tensor-like object (e.g., torch.Tensor, numpy.ndarray) containing the image data.</p> required <code>peak_coords</code> <code>torch.Tensor, np.ndarray, or pd.DataFrame</code> <p>A tensor-like object of shape (n, 2) containing the initial peak coordinates (y, x).</p> required <code>boxsize</code> <code>int</code> <p>Size of the region to crop around each peak (must be even).</p> required <code>max_iterations</code> <code>int</code> <p>Maximum number of optimization iterations. Default is 1000.</p> <code>1000</code> <code>learning_rate</code> <code>float</code> <p>Learning rate for the optimizer. Default is 0.01.</p> <code>0.01</code> <code>tolerance</code> <code>float</code> <p>Convergence tolerance for the optimization. Default is 1e-6.</p> <code>1e-06</code> <code>amplitude</code> <code>Union[Tensor, float]</code> <p>Initial amplitude of the Gaussian. Default is 1.0.</p> <code>1.0</code> <code>sigma_x</code> <code>Union[Tensor, float]</code> <p>Initial standard deviation in the x direction. Default is 1.0.</p> <code>1.0</code> <code>sigma_y</code> <code>Union[Tensor, float]</code> <p>Initial standard deviation in the y direction. Default is 1.0.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (n, 5) containing the fitted parameters for each peak. Each row contains [amplitude, y, x, sigma_x, sigma_y].</p> Source code in <code>src/torch_find_peaks/refine_peaks.py</code> <pre><code>def refine_peaks_2d(\n    image: Any,\n    peak_coords: Union[torch.Tensor, np.ndarray, pd.DataFrame],\n    boxsize: int,\n    max_iterations: int = 1000,\n    learning_rate: float = 0.01,\n    tolerance: float = 1e-6,\n    amplitude: Union[torch.Tensor, float] = 1.,\n    sigma_x: Union[torch.Tensor, float] = 1.,\n    sigma_y: Union[torch.Tensor, float] = 1.,\n    return_as: Literal[\"torch\", \"numpy\", \"dataframe\"] = \"torch\",\n) -&gt; torch.Tensor:\n    \"\"\"\n    Refine the positions of peaks in a 2D image by fitting 2D Gaussian functions.\n\n    Parameters\n    ----------\n    image : Any\n        A 2D tensor-like object (e.g., torch.Tensor, numpy.ndarray)\n        containing the image data.\n    peak_coords : torch.Tensor, np.ndarray, or pd.DataFrame\n        A tensor-like object of shape (n, 2) containing the initial peak coordinates (y, x).\n    boxsize : int\n        Size of the region to crop around each peak (must be even).\n    max_iterations : int, optional\n        Maximum number of optimization iterations. Default is 1000.\n    learning_rate : float, optional\n        Learning rate for the optimizer. Default is 0.01.\n    tolerance : float, optional\n        Convergence tolerance for the optimization. Default is 1e-6.\n    amplitude : Union[torch.Tensor, float], optional\n        Initial amplitude of the Gaussian. Default is 1.0.\n    sigma_x : Union[torch.Tensor, float], optional\n        Initial standard deviation in the x direction. Default is 1.0.\n    sigma_y : Union[torch.Tensor, float], optional\n        Initial standard deviation in the y direction. Default is 1.0.\n\n    Returns\n    -------\n    torch.Tensor\n        A tensor of shape (n, 5) containing the fitted parameters for each peak.\n        Each row contains [amplitude, y, x, sigma_x, sigma_y].\n    \"\"\"\n    if not isinstance(image, torch.Tensor):\n        image = torch.as_tensor(image)\n    if isinstance(peak_coords, pd.DataFrame):\n        amplitude = torch.as_tensor(peak_coords[\"height\"].to_numpy())\n        peak_coords = torch.as_tensor(peak_coords[[\"y\",\"x\"]].to_numpy())\n    if not isinstance(peak_coords, torch.Tensor):\n        peak_coords = torch.as_tensor(peak_coords)\n\n    num_peaks = peak_coords.shape[0]\n    if not isinstance(amplitude, torch.Tensor):\n        amplitude = torch.tensor([amplitude] * num_peaks, device=image.device)\n    if not isinstance(sigma_x, torch.Tensor):\n        sigma_x = torch.tensor([sigma_x] * num_peaks, device=image.device)\n    if not isinstance(sigma_y, torch.Tensor):\n        sigma_y = torch.tensor([sigma_y] * num_peaks, device=image.device)\n\n    initial_peak_data = torch.stack([\n        amplitude,\n        peak_coords[:, 0],  # y\n        peak_coords[:, 1],  # x\n        sigma_x,\n        sigma_y,\n    ], dim=-1)\n\n    refined_peak_data = _refine_peaks_2d_torch(\n        image=image,\n        peak_data=initial_peak_data,\n        boxsize=boxsize,\n        max_iterations=max_iterations,\n        learning_rate=learning_rate,\n        tolerance=tolerance,\n    )\n\n    if return_as==\"torch\":\n        return refined_peak_data\n    elif return_as==\"numpy\":\n        return refined_peak_data.detach().cpu().numpy()\n    elif return_as==\"dataframe\":\n        return pd.DataFrame(refined_peak_data.detach().cpu().numpy(), columns=[\"amplitude\", \"y\", \"x\", \"sigma_x\", \"sigma_y\"])\n    else:\n        raise ValueError(f\"Invalid return_as value: {return_as}\")\n</code></pre>"},{"location":"#torch_find_peaks.refine_peaks.refine_peaks_3d","title":"<code>refine_peaks_3d(volume, peak_coords, boxsize, max_iterations=1000, learning_rate=0.01, tolerance=1e-06, amplitude=1.0, sigma_x=1.0, sigma_y=1.0, sigma_z=1.0, return_as='torch')</code>","text":"<p>Refine the positions of peaks in a 3D volume by fitting 3D Gaussian functions.</p> <p>Parameters:</p> Name Type Description Default <code>volume</code> <code>Any</code> <p>A 3D tensor-like object (e.g., torch.Tensor, numpy.ndarray) containing the volume data.</p> required <code>peak_coords</code> <code>torch.Tensor, np.ndarray, or pd.DataFrame</code> <p>A tensor-like object of shape (n, 3) containing the initial peak coordinates (z, y, x).</p> required <code>boxsize</code> <code>int</code> <p>Size of the region to crop around each peak (must be even).</p> required <code>max_iterations</code> <code>int</code> <p>Maximum number of optimization iterations. Default is 1000.</p> <code>1000</code> <code>learning_rate</code> <code>float</code> <p>Learning rate for the optimizer. Default is 0.01.</p> <code>0.01</code> <code>tolerance</code> <code>float</code> <p>Convergence tolerance for the optimization. Default is 1e-6.</p> <code>1e-06</code> <code>amplitude</code> <code>Union[Tensor, float]</code> <p>Initial amplitude of the Gaussian. Default is 1.0.</p> <code>1.0</code> <code>sigma_x</code> <code>Union[Tensor, float]</code> <p>Initial standard deviation in the x direction. Default is 1.0.</p> <code>1.0</code> <code>sigma_y</code> <code>Union[Tensor, float]</code> <p>Initial standard deviation in the y direction. Default is 1.0.</p> <code>1.0</code> <code>sigma_z</code> <code>Union[Tensor, float]</code> <p>Initial standard deviation in the z direction. Default is 1.0.</p> <code>1.0</code> <p>Returns:</p> Type Description <code>Tensor</code> <p>A tensor of shape (n, 7) containing the fitted parameters for each peak. Each row contains [amplitude, z, y, x, sigma_x, sigma_y, sigma_z].</p> Source code in <code>src/torch_find_peaks/refine_peaks.py</code> <pre><code>def refine_peaks_3d(\n    volume: Any,\n    peak_coords: Union[torch.Tensor, np.ndarray, pd.DataFrame],\n    boxsize: int,\n    max_iterations: int = 1000,\n    learning_rate: float = 0.01,\n    tolerance: float = 1e-6,\n    amplitude: Union[torch.Tensor, float] = 1.,\n    sigma_x: Union[torch.Tensor, float] = 1.,\n    sigma_y: Union[torch.Tensor, float] = 1.,\n    sigma_z: Union[torch.Tensor, float] = 1.,\n    return_as: Literal[\"torch\", \"numpy\", \"dataframe\"] = \"torch\",\n) -&gt; torch.Tensor:\n    \"\"\"\n    Refine the positions of peaks in a 3D volume by fitting 3D Gaussian functions.\n\n    Parameters\n    ----------\n    volume : Any\n        A 3D tensor-like object (e.g., torch.Tensor, numpy.ndarray)\n        containing the volume data.\n    peak_coords : torch.Tensor, np.ndarray, or pd.DataFrame\n        A tensor-like object of shape (n, 3) containing the initial peak coordinates (z, y, x).\n    boxsize : int\n        Size of the region to crop around each peak (must be even).\n    max_iterations : int, optional\n        Maximum number of optimization iterations. Default is 1000.\n    learning_rate : float, optional\n        Learning rate for the optimizer. Default is 0.01.\n    tolerance : float, optional\n        Convergence tolerance for the optimization. Default is 1e-6.\n    amplitude : Union[torch.Tensor, float], optional\n        Initial amplitude of the Gaussian. Default is 1.0.\n    sigma_x : Union[torch.Tensor, float], optional\n        Initial standard deviation in the x direction. Default is 1.0.\n    sigma_y : Union[torch.Tensor, float], optional\n        Initial standard deviation in the y direction. Default is 1.0.\n    sigma_z : Union[torch.Tensor, float], optional\n        Initial standard deviation in the z direction. Default is 1.0.\n\n    Returns\n    -------\n    torch.Tensor\n        A tensor of shape (n, 7) containing the fitted parameters for each peak.\n        Each row contains [amplitude, z, y, x, sigma_x, sigma_y, sigma_z].\n    \"\"\"\n    if not isinstance(volume, torch.Tensor):\n        volume = torch.as_tensor(volume)\n    if isinstance(peak_coords, pd.DataFrame):\n        amplitude = torch.as_tensor(peak_coords[\"height\"].to_numpy(),device=volume.device)\n        peak_coords = torch.as_tensor(peak_coords[[\"z\", \"y\", \"x\"]].to_numpy(),device=volume.device)\n    if not isinstance(peak_coords, torch.Tensor):\n        peak_coords = torch.as_tensor(peak_coords)\n\n    num_peaks = peak_coords.shape[0]\n    if not isinstance(amplitude, torch.Tensor):\n        amplitude = torch.tensor([amplitude] * num_peaks, device=volume.device)\n    if not isinstance(sigma_x, torch.Tensor):\n        sigma_x = torch.tensor([sigma_x] * num_peaks, device=volume.device)\n    if not isinstance(sigma_y, torch.Tensor):\n        sigma_y = torch.tensor([sigma_y] * num_peaks, device=volume.device)\n    if not isinstance(sigma_z, torch.Tensor):\n        sigma_z = torch.tensor([sigma_z] * num_peaks, device=volume.device)\n\n    initial_peak_data = torch.stack([\n        amplitude,\n        peak_coords[:, 0],  # z\n        peak_coords[:, 1],  # y\n        peak_coords[:, 2],  # x\n        sigma_x,\n        sigma_y,\n        sigma_z,\n    ], dim=-1)\n\n    refined_peak_data, boxes, output = _refine_peaks_3d_torch(\n        volume=volume,\n        peak_data=initial_peak_data,\n        boxsize=boxsize,\n        max_iterations=max_iterations,\n        learning_rate=learning_rate,\n        tolerance=tolerance,\n    )\n\n    if return_as == \"torch\":\n        return refined_peak_data\n    elif return_as == \"numpy\":\n        return refined_peak_data.detach().cpu().numpy()\n    elif return_as == \"dataframe\":\n        return pd.DataFrame(refined_peak_data.detach().cpu().numpy(), columns=[\"amplitude\", \"z\", \"y\", \"x\", \"sigma_x\", \"sigma_y\", \"sigma_z\"])\n    else:\n        raise ValueError(f\"Invalid return_as value: {return_as}\")\n</code></pre>"},{"location":"#torch_find_peaksgaussians","title":"<code>torch_find_peaks.gaussians</code>","text":""},{"location":"#torch_find_peaks.gaussians.Gaussian2D","title":"<code>Gaussian2D</code>","text":"<p>               Bases: <code>Module</code></p> <p>A 2D Gaussian function.</p> <p>Parameters:</p> Name Type Description Default <code>amplitude</code> <code>tensor</code> <p>Amplitude of the Gaussian. Default is torch.tensor([1.0]).</p> <code>1.0</code> <code>center_y</code> <code>tensor</code> <p>Y-coordinate of the center. Default is torch.tensor([0.0]).</p> <code>0.0</code> <code>center_x</code> <code>tensor</code> <p>X-coordinate of the center. Default is torch.tensor([0.0]).</p> <code>0.0</code> <code>sigma_y</code> <code>tensor</code> <p>Standard deviation along the y-axis. Default is torch.tensor([1.0]).</p> <code>1.0</code> <code>sigma_x</code> <code>tensor</code> <p>Standard deviation along the x-axis. Default is torch.tensor([1.0]).</p> <code>1.0</code> <p>Methods:</p> Name Description <code>forward</code> <p>Compute the Gaussian values for a given 2D grid. Expects grid in yx order (grid[..., 0] is y, grid[..., 1] is x).</p> Source code in <code>src/torch_find_peaks/gaussians.py</code> <pre><code>class Gaussian2D(nn.Module):\n    \"\"\"\n    A 2D Gaussian function.\n\n    Parameters\n    ----------\n    amplitude : torch.tensor, optional\n        Amplitude of the Gaussian. Default is torch.tensor([1.0]).\n    center_y : torch.tensor, optional\n        Y-coordinate of the center. Default is torch.tensor([0.0]).\n    center_x : torch.tensor, optional\n        X-coordinate of the center. Default is torch.tensor([0.0]).\n    sigma_y : torch.tensor, optional\n        Standard deviation along the y-axis. Default is torch.tensor([1.0]).\n    sigma_x : torch.tensor, optional\n        Standard deviation along the x-axis. Default is torch.tensor([1.0]).\n\n    Methods\n    -------\n    forward(grid)\n        Compute the Gaussian values for a given 2D grid.\n        Expects grid in yx order (grid[..., 0] is y, grid[..., 1] is x).\n    \"\"\"\n\n    def __init__(self,\n                 amplitude: Union[torch.Tensor | float] = 1.0,\n                 center_y: Union[torch.Tensor | float] = 0.0,\n                 center_x: Union[torch.Tensor | float] = 0.0,\n                 sigma_y: Union[torch.Tensor | float] = 1.0,\n                 sigma_x: Union[torch.Tensor | float] = 1.0\n    ):\n        super(Gaussian2D, self).__init__()\n        # Ensure that the parameters are tensors\n        if not isinstance(amplitude, torch.Tensor):\n            amplitude = torch.tensor(amplitude)\n        if not isinstance(center_y, torch.Tensor):\n            center_y = torch.tensor(center_y)\n        if not isinstance(center_x, torch.Tensor):\n            center_x = torch.tensor(center_x)\n        if not isinstance(sigma_y, torch.Tensor):\n            sigma_y = torch.tensor(sigma_y)\n        if not isinstance(sigma_x, torch.Tensor):\n            sigma_x = torch.tensor(sigma_x)\n        # Check if all parameters are of the same shape\n        assert amplitude.shape == center_y.shape == center_x.shape == sigma_y.shape == sigma_x.shape, \\\n            \"All parameters must have the same shape.\"\n\n        self.amplitude = nn.Parameter(amplitude)\n        self.center_y = nn.Parameter(center_y)\n        self.center_x = nn.Parameter(center_x)\n        self.sigma_y = nn.Parameter(sigma_y)\n        self.sigma_x = nn.Parameter(sigma_x)\n\n    def forward(self, grid):\n        \"\"\"\n        Forward pass for 2D Gaussian list.\n\n        Args:\n            grid: Tensor of shape (h,w, 2) containing 2D coordinates in yx order.\n\n        Returns\n        -------\n            Tensor of Gaussian values\n        \"\"\"\n        # Add batch dimension\n        grid_x = einops.rearrange(grid[..., 1], 'h w -&gt; h w' + ' 1'*self.amplitude.dim())\n        grid_y = einops.rearrange(grid[..., 0], 'h w -&gt; h w' + ' 1'*self.amplitude.dim())\n\n        amplitude = einops.rearrange(self.amplitude, '... -&gt; 1 1 ...')\n        center_x = einops.rearrange(self.center_x, '... -&gt; 1 1 ...')\n        center_y = einops.rearrange(self.center_y, '... -&gt; 1 1 ...')\n        sigma_x = einops.rearrange(self.sigma_x, '... -&gt; 1 1 ...')\n        sigma_y = einops.rearrange(self.sigma_y, '... -&gt; 1 1 ...')\n\n        gaussian = amplitude * torch.exp(\n            -((grid_x - center_x) ** 2 / (2 * sigma_x ** 2) +\n              (grid_y - center_y) ** 2 / (2 * sigma_y ** 2))\n        )\n\n        return einops.rearrange(gaussian, 'h w ... -&gt; ... h w')\n</code></pre>"},{"location":"#torch_find_peaks.gaussians.Gaussian2D.forward","title":"<code>forward(grid)</code>","text":"<p>Forward pass for 2D Gaussian list.</p> <p>Args:     grid: Tensor of shape (h,w, 2) containing 2D coordinates in yx order.</p> <p>Returns:</p> Type Description <code>    Tensor of Gaussian values</code> Source code in <code>src/torch_find_peaks/gaussians.py</code> <pre><code>def forward(self, grid):\n    \"\"\"\n    Forward pass for 2D Gaussian list.\n\n    Args:\n        grid: Tensor of shape (h,w, 2) containing 2D coordinates in yx order.\n\n    Returns\n    -------\n        Tensor of Gaussian values\n    \"\"\"\n    # Add batch dimension\n    grid_x = einops.rearrange(grid[..., 1], 'h w -&gt; h w' + ' 1'*self.amplitude.dim())\n    grid_y = einops.rearrange(grid[..., 0], 'h w -&gt; h w' + ' 1'*self.amplitude.dim())\n\n    amplitude = einops.rearrange(self.amplitude, '... -&gt; 1 1 ...')\n    center_x = einops.rearrange(self.center_x, '... -&gt; 1 1 ...')\n    center_y = einops.rearrange(self.center_y, '... -&gt; 1 1 ...')\n    sigma_x = einops.rearrange(self.sigma_x, '... -&gt; 1 1 ...')\n    sigma_y = einops.rearrange(self.sigma_y, '... -&gt; 1 1 ...')\n\n    gaussian = amplitude * torch.exp(\n        -((grid_x - center_x) ** 2 / (2 * sigma_x ** 2) +\n          (grid_y - center_y) ** 2 / (2 * sigma_y ** 2))\n    )\n\n    return einops.rearrange(gaussian, 'h w ... -&gt; ... h w')\n</code></pre>"},{"location":"#torch_find_peaks.gaussians.Gaussian3D","title":"<code>Gaussian3D</code>","text":"<p>               Bases: <code>Module</code></p> <p>A 3D Gaussian function.</p> <p>Parameters:</p> Name Type Description Default <code>amplitude</code> <code>tensor</code> <p>Amplitude of the Gaussian. Default is torch.tensor([1.0]).</p> <code>1.0</code> <code>center_z</code> <code>tensor</code> <p>Z-coordinate of the center. Default is torch.tensor([0.0]).</p> <code>0.0</code> <code>center_y</code> <code>tensor</code> <p>Y-coordinate of the center. Default is torch.tensor([0.0]).</p> <code>0.0</code> <code>center_x</code> <code>tensor</code> <p>X-coordinate of the center. Default is torch.tensor([0.0]).</p> <code>0.0</code> <code>sigma_z</code> <code>tensor</code> <p>Standard deviation along the z-axis. Default is torch.tensor([1.0]).</p> <code>1.0</code> <code>sigma_y</code> <code>tensor</code> <p>Standard deviation along the y-axis. Default is torch.tensor([1.0]).</p> <code>1.0</code> <code>sigma_x</code> <code>tensor</code> <p>Standard deviation along the x-axis. Default is torch.tensor([1.0]).</p> <code>1.0</code> <p>Methods:</p> Name Description <code>forward</code> <p>Compute the Gaussian values for a given 3D grid. Expects grid in zyx order (grid[..., 0] is z, grid[..., 1] is y, grid[..., 2] is x).</p> Source code in <code>src/torch_find_peaks/gaussians.py</code> <pre><code>class Gaussian3D(nn.Module):\n    \"\"\"\n    A 3D Gaussian function.\n\n    Parameters\n    ----------\n    amplitude : torch.tensor, optional\n        Amplitude of the Gaussian. Default is torch.tensor([1.0]).\n    center_z : torch.tensor, optional\n        Z-coordinate of the center. Default is torch.tensor([0.0]).\n    center_y : torch.tensor, optional\n        Y-coordinate of the center. Default is torch.tensor([0.0]).\n    center_x : torch.tensor, optional\n        X-coordinate of the center. Default is torch.tensor([0.0]).\n    sigma_z : torch.tensor, optional\n        Standard deviation along the z-axis. Default is torch.tensor([1.0]).\n    sigma_y : torch.tensor, optional\n        Standard deviation along the y-axis. Default is torch.tensor([1.0]).\n    sigma_x : torch.tensor, optional\n        Standard deviation along the x-axis. Default is torch.tensor([1.0]).\n\n    Methods\n    -------\n    forward(grid)\n        Compute the Gaussian values for a given 3D grid.\n        Expects grid in zyx order (grid[..., 0] is z, grid[..., 1] is y, grid[..., 2] is x).\n    \"\"\"\n\n    def __init__(self,\n                 amplitude: Union[torch.Tensor | float] = 1.0,\n                 center_z: Union[torch.Tensor | float] = 0.0,\n                 center_y: Union[torch.Tensor | float] = 0.0,\n                 center_x: Union[torch.Tensor | float] = 0.0,\n                 sigma_z: Union[torch.Tensor | float] = 1.0,\n                 sigma_y: Union[torch.Tensor | float] = 1.0,\n                 sigma_x: Union[torch.Tensor | float] = 1.0\n    ):\n        super(Gaussian3D, self).__init__()\n        # Ensure that the parameters are tensors\n        if not isinstance(amplitude, torch.Tensor):\n            amplitude = torch.tensor(amplitude)\n        if not isinstance(center_z, torch.Tensor):\n            center_z = torch.tensor(center_z)\n        if not isinstance(center_y, torch.Tensor):\n            center_y = torch.tensor(center_y)\n        if not isinstance(center_x, torch.Tensor):\n            center_x = torch.tensor(center_x)\n        if not isinstance(sigma_z, torch.Tensor):\n            sigma_z = torch.tensor(sigma_z)\n        if not isinstance(sigma_y, torch.Tensor):\n            sigma_y = torch.tensor(sigma_y)\n        if not isinstance(sigma_x, torch.Tensor):\n            sigma_x = torch.tensor(sigma_x)\n        # Check if all parameters are of the same shape\n        assert amplitude.shape == center_z.shape == center_y.shape == center_x.shape == sigma_z.shape == sigma_y.shape == sigma_x.shape, \\\n            \"All parameters must have the same shape.\"\n\n        self.amplitude = nn.Parameter(amplitude)\n        self.center_z = nn.Parameter(center_z)\n        self.center_y = nn.Parameter(center_y)\n        self.center_x = nn.Parameter(center_x)\n        self.sigma_z = nn.Parameter(sigma_z)\n        self.sigma_y = nn.Parameter(sigma_y)\n        self.sigma_x = nn.Parameter(sigma_x)\n\n    def forward(self, grid):\n        \"\"\"\n        Forward pass for 3D Gaussian list.\n\n        Args:\n            grid: Tensor of shape (d, h, w, 3) containing 3D coordinates in zyx order \n                 (grid[..., 0] is z, grid[..., 1] is y, grid[..., 2] is x).\n\n        Returns\n        -------\n            Tensor of Gaussian values\n        \"\"\"\n         # Add batch dimension\n        grid_x = einops.rearrange(grid[..., 2], 'd h w -&gt; d h w' + ' 1'*self.amplitude.dim())\n        grid_y = einops.rearrange(grid[..., 1], 'd h w -&gt; d h w' + ' 1'*self.amplitude.dim())\n        grid_z = einops.rearrange(grid[..., 0], 'd h w -&gt; d h w' + ' 1'*self.amplitude.dim())\n\n        amplitude = einops.rearrange(self.amplitude, '... -&gt; 1 1 1 ...')\n        center_x = einops.rearrange(self.center_x, '... -&gt; 1 1 1 ...')\n        center_y = einops.rearrange(self.center_y, '... -&gt; 1 1 1 ...')\n        center_z = einops.rearrange(self.center_z, '... -&gt; 1 1 1 ...')\n        sigma_x = einops.rearrange(self.sigma_x, '... -&gt; 1 1 1 ...')\n        sigma_y = einops.rearrange(self.sigma_y, '... -&gt; 1 1 1 ...')\n        sigma_z = einops.rearrange(self.sigma_z, '... -&gt; 1 1 1 ...')\n\n\n        gaussian = amplitude * torch.exp(\n            -((grid_x - center_x) ** 2 / (2 * sigma_x ** 2) +\n              (grid_y - center_y) ** 2 / (2 * sigma_y ** 2) +\n              (grid_z - center_z) ** 2 / (2 * sigma_z ** 2))\n        )\n\n        return einops.rearrange(gaussian, 'd h w ... -&gt; ... d h w')\n</code></pre>"},{"location":"#torch_find_peaks.gaussians.Gaussian3D.forward","title":"<code>forward(grid)</code>","text":"<p>Forward pass for 3D Gaussian list.</p> <p>Args:     grid: Tensor of shape (d, h, w, 3) containing 3D coordinates in zyx order           (grid[..., 0] is z, grid[..., 1] is y, grid[..., 2] is x).</p> <p>Returns:</p> Type Description <code>    Tensor of Gaussian values</code> Source code in <code>src/torch_find_peaks/gaussians.py</code> <pre><code>def forward(self, grid):\n    \"\"\"\n    Forward pass for 3D Gaussian list.\n\n    Args:\n        grid: Tensor of shape (d, h, w, 3) containing 3D coordinates in zyx order \n             (grid[..., 0] is z, grid[..., 1] is y, grid[..., 2] is x).\n\n    Returns\n    -------\n        Tensor of Gaussian values\n    \"\"\"\n     # Add batch dimension\n    grid_x = einops.rearrange(grid[..., 2], 'd h w -&gt; d h w' + ' 1'*self.amplitude.dim())\n    grid_y = einops.rearrange(grid[..., 1], 'd h w -&gt; d h w' + ' 1'*self.amplitude.dim())\n    grid_z = einops.rearrange(grid[..., 0], 'd h w -&gt; d h w' + ' 1'*self.amplitude.dim())\n\n    amplitude = einops.rearrange(self.amplitude, '... -&gt; 1 1 1 ...')\n    center_x = einops.rearrange(self.center_x, '... -&gt; 1 1 1 ...')\n    center_y = einops.rearrange(self.center_y, '... -&gt; 1 1 1 ...')\n    center_z = einops.rearrange(self.center_z, '... -&gt; 1 1 1 ...')\n    sigma_x = einops.rearrange(self.sigma_x, '... -&gt; 1 1 1 ...')\n    sigma_y = einops.rearrange(self.sigma_y, '... -&gt; 1 1 1 ...')\n    sigma_z = einops.rearrange(self.sigma_z, '... -&gt; 1 1 1 ...')\n\n\n    gaussian = amplitude * torch.exp(\n        -((grid_x - center_x) ** 2 / (2 * sigma_x ** 2) +\n          (grid_y - center_y) ** 2 / (2 * sigma_y ** 2) +\n          (grid_z - center_z) ** 2 / (2 * sigma_z ** 2))\n    )\n\n    return einops.rearrange(gaussian, 'd h w ... -&gt; ... d h w')\n</code></pre>"},{"location":"#torch_find_peaks.gaussians.WarpedGaussian2D","title":"<code>WarpedGaussian2D</code>","text":"<p>               Bases: <code>Module</code></p> <p>A 2D warped Gaussian function.</p> <p>Parameters:</p> Name Type Description Default <code>amplitude</code> <code>tensor</code> <p>Amplitude of the Gaussian. Default is torch.tensor([1.0]).</p> <code>tensor([1.0])</code> <code>center_y</code> <code>tensor</code> <p>Y-coordinate of the center. Default is torch.tensor([0.0]).</p> <code>tensor([0.0])</code> <code>center_x</code> <code>tensor</code> <p>X-coordinate of the center. Default is torch.tensor([0.0]).</p> <code>tensor([0.0])</code> <code>sigma_y</code> <code>tensor</code> <p>Standard deviation along the y-axis. Default is torch.tensor([1.0]).</p> <code>tensor([1.0])</code> <code>sigma_x</code> <code>tensor</code> <p>Standard deviation along the x-axis. Default is torch.tensor([1.0]).</p> <code>tensor([1.0])</code> <code>warp</code> <code>tensor</code> <p>Warp factor for the Gaussian. Default is torch.tensor([1.0]).</p> <code>tensor([1.0])</code> <code>warp_angle</code> <code>tensor</code> <p>Angle of the warp in radians. Default is torch.tensor([0.0]).</p> <code>tensor([0.0])</code> <p>Methods:</p> Name Description <code>forward</code> <p>Compute the warped Gaussian values for a given 2D grid. Expects grid in yx order (grid[..., 0] is y, grid[..., 1] is x).</p> Source code in <code>src/torch_find_peaks/gaussians.py</code> <pre><code>class WarpedGaussian2D(nn.Module):\n    \"\"\"\n    A 2D warped Gaussian function.\n\n    Parameters\n    ----------\n    amplitude : torch.tensor, optional\n        Amplitude of the Gaussian. Default is torch.tensor([1.0]).\n    center_y : torch.tensor, optional\n        Y-coordinate of the center. Default is torch.tensor([0.0]).\n    center_x : torch.tensor, optional\n        X-coordinate of the center. Default is torch.tensor([0.0]).\n    sigma_y : torch.tensor, optional\n        Standard deviation along the y-axis. Default is torch.tensor([1.0]).\n    sigma_x : torch.tensor, optional\n        Standard deviation along the x-axis. Default is torch.tensor([1.0]).\n    warp : torch.tensor, optional\n        Warp factor for the Gaussian. Default is torch.tensor([1.0]).\n    warp_angle : torch.tensor, optional\n        Angle of the warp in radians. Default is torch.tensor([0.0]).\n\n    Methods\n    -------\n    forward(grid)\n        Compute the warped Gaussian values for a given 2D grid.\n        Expects grid in yx order (grid[..., 0] is y, grid[..., 1] is x).\n    \"\"\"\n\n    def __init__(self,\n                 amplitude: torch.tensor = torch.tensor([1.0]),\n                 center_y: torch.tensor = torch.tensor([0.0]),\n                 center_x: torch.tensor = torch.tensor([0.0]),\n                 sigma_y: torch.tensor = torch.tensor([1.0]),\n                 sigma_x: torch.tensor = torch.tensor([1.0]),\n                 warp: torch.tensor = torch.tensor([1.0]),\n                 warp_angle: torch.tensor = torch.tensor([0.0])\n    ):\n        super(WarpedGaussian2D, self).__init__()\n        # Ensure that the parameters are tensors\n        if not isinstance(amplitude, torch.Tensor):\n            amplitude = torch.tensor(amplitude)\n        if not isinstance(center_y, torch.Tensor):\n            center_y = torch.tensor(center_y)\n        if not isinstance(center_x, torch.Tensor):\n            center_x = torch.tensor(center_x)\n        if not isinstance(sigma_y, torch.Tensor):\n            sigma_y = torch.tensor(sigma_y)\n        if not isinstance(sigma_x, torch.Tensor):\n            sigma_x = torch.tensor(sigma_x)\n        if not isinstance(warp, torch.Tensor):\n            warp = torch.tensor(warp)\n        if not isinstance(warp_angle, torch.Tensor):\n            warp_angle = torch.tensor(warp_angle)\n        # Check if all parameters are of the same shape\n        assert amplitude.shape == center_y.shape == center_x.shape == sigma_y.shape == sigma_x.shape == warp.shape == warp_angle.shape, \\\n            \"All parameters must have the same shape.\"\n\n        self.amplitude = nn.Parameter(amplitude)\n        self.center_y = nn.Parameter(center_y)\n        self.center_x = nn.Parameter(center_x)\n        self.sigma_y = nn.Parameter(sigma_y)\n        self.sigma_x = nn.Parameter(sigma_x)\n        self.warp = nn.Parameter(warp)\n        self.warp_angle = nn.Parameter(warp_angle)\n\n    def forward(self, grid):\n        \"\"\"\n        Forward pass for 2D warped Gaussian list.\n\n        Args:\n            grid: Tensor of shape (h,w, 2) containing 2D coordinates in yx order.\n\n        Returns\n        -------\n            Tensor of warped Gaussian values\n        \"\"\"\n        amplitude = einops.rearrange(self.amplitude, '... -&gt; 1 1 ...')\n        center_x = einops.rearrange(self.center_x, '... -&gt; 1 1 ...')\n        center_y = einops.rearrange(self.center_y, '... -&gt; 1 1 ...')\n        sigma_x = einops.rearrange(self.sigma_x, '... -&gt; 1 1 ...')\n        sigma_y = einops.rearrange(self.sigma_y, '... -&gt; 1 1 ...')\n        warp = einops.rearrange(self.warp, '... -&gt; 1 1 ...')\n        warp_angle = einops.rearrange(self.warp_angle, '... -&gt; 1 1 ...')\n\n        grid_x = einops.rearrange(grid[..., 1], 'h w -&gt; h w 1')\n        grid_y = einops.rearrange(grid[..., 0], 'h w -&gt; h w 1')\n\n        u = (grid_x - center_x) * torch.cos(warp_angle) - (grid_y - center_y) * torch.sin(warp_angle)\n        v = (grid_x - center_x) * torch.sin(warp_angle) + (grid_y - center_y) * torch.cos(warp_angle)\n\n        warped_gaussian = amplitude * torch.exp(\n            -((u - warp * v ** 2) ** 2 / (2 * sigma_x ** 2) +\n              v ** 2 / (2 * sigma_y ** 2))\n        )\n\n        return einops.rearrange(warped_gaussian, 'h w ... -&gt; ... h w')\n</code></pre>"},{"location":"#torch_find_peaks.gaussians.WarpedGaussian2D.forward","title":"<code>forward(grid)</code>","text":"<p>Forward pass for 2D warped Gaussian list.</p> <p>Args:     grid: Tensor of shape (h,w, 2) containing 2D coordinates in yx order.</p> <p>Returns:</p> Type Description <code>    Tensor of warped Gaussian values</code> Source code in <code>src/torch_find_peaks/gaussians.py</code> <pre><code>def forward(self, grid):\n    \"\"\"\n    Forward pass for 2D warped Gaussian list.\n\n    Args:\n        grid: Tensor of shape (h,w, 2) containing 2D coordinates in yx order.\n\n    Returns\n    -------\n        Tensor of warped Gaussian values\n    \"\"\"\n    amplitude = einops.rearrange(self.amplitude, '... -&gt; 1 1 ...')\n    center_x = einops.rearrange(self.center_x, '... -&gt; 1 1 ...')\n    center_y = einops.rearrange(self.center_y, '... -&gt; 1 1 ...')\n    sigma_x = einops.rearrange(self.sigma_x, '... -&gt; 1 1 ...')\n    sigma_y = einops.rearrange(self.sigma_y, '... -&gt; 1 1 ...')\n    warp = einops.rearrange(self.warp, '... -&gt; 1 1 ...')\n    warp_angle = einops.rearrange(self.warp_angle, '... -&gt; 1 1 ...')\n\n    grid_x = einops.rearrange(grid[..., 1], 'h w -&gt; h w 1')\n    grid_y = einops.rearrange(grid[..., 0], 'h w -&gt; h w 1')\n\n    u = (grid_x - center_x) * torch.cos(warp_angle) - (grid_y - center_y) * torch.sin(warp_angle)\n    v = (grid_x - center_x) * torch.sin(warp_angle) + (grid_y - center_y) * torch.cos(warp_angle)\n\n    warped_gaussian = amplitude * torch.exp(\n        -((u - warp * v ** 2) ** 2 / (2 * sigma_x ** 2) +\n          v ** 2 / (2 * sigma_y ** 2))\n    )\n\n    return einops.rearrange(warped_gaussian, 'h w ... -&gt; ... h w')\n</code></pre>"},{"location":"examples/find_golds/","title":"Find golds","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport mrcfile\nimport pooch\nimport torch\nfrom torch_find_peaks.find_peaks import find_peaks_3d\nfrom torch_find_peaks.refine_peaks import refine_peaks_3d\n</pre> import matplotlib.pyplot as plt import mrcfile import pooch import torch from torch_find_peaks.find_peaks import find_peaks_3d from torch_find_peaks.refine_peaks import refine_peaks_3d In\u00a0[2]: Copied! <pre>tomo = pooch.retrieve(\"https://ftp.ebi.ac.uk/pub/databases/emdb/structures/EMD-25061/map/emd_25061.map.gz\",known_hash=None)\n</pre>  tomo = pooch.retrieve(\"https://ftp.ebi.ac.uk/pub/databases/emdb/structures/EMD-25061/map/emd_25061.map.gz\",known_hash=None)  In\u00a0[3]: Copied! <pre>with mrcfile.open(tomo, mode='r') as mrc:\n    # print the map header\n    tomo_data = torch.tensor(mrc.data).to(\"cuda:0\")\n</pre> with mrcfile.open(tomo, mode='r') as mrc:     # print the map header     tomo_data = torch.tensor(mrc.data).to(\"cuda:0\")  In\u00a0[4]: Copied! <pre>with torch.inference_mode():\n    # Find peaks in the 3D volume\n    peak_data = find_peaks_3d(\n                volume = -1. * tomo_data + torch.randn_like(tomo_data,dtype=torch.float32) * 0.001,\n                threshold_abs=30,\n                min_distance=5,\n                return_as=\"dataframe\"\n            )\n</pre> with torch.inference_mode():     # Find peaks in the 3D volume     peak_data = find_peaks_3d(                 volume = -1. * tomo_data + torch.randn_like(tomo_data,dtype=torch.float32) * 0.001,                 threshold_abs=30,                 min_distance=5,                 return_as=\"dataframe\"             ) In\u00a0[5]: Copied! <pre>peak_data\n</pre> peak_data Out[5]: z y x height 0 55.0 1446.0 515.0 128.003265 1 61.0 1449.0 516.0 128.001999 2 105.0 1052.0 247.0 128.001465 3 113.0 1185.0 134.0 61.999825 4 114.0 1211.0 154.0 69.000458 ... ... ... ... ... 263 437.0 206.0 535.0 113.000702 264 448.0 149.0 634.0 87.997681 265 451.0 459.0 154.0 86.999817 266 457.0 473.0 177.0 122.000229 267 487.0 262.0 2.0 39.000031 <p>268 rows \u00d7 4 columns</p> In\u00a0[6]: Copied! <pre>import imodmodel\n\nimodmodel.write(peak_data, \"test.mod\")\n</pre> import imodmodel  imodmodel.write(peak_data, \"test.mod\") In\u00a0[7]: Copied! <pre>fig, [pl1, pl2] = plt.subplots(1, 2, figsize=(6, 4))\ntomo_data_cpu = tomo_data.cpu()\npl1.imshow(torch.min(tomo_data_cpu, dim=0).values, cmap='gray',interpolation='mitchell', vmin=0, vmax=70)\npl2.imshow(torch.min(tomo_data_cpu, dim=0).values, cmap='gray',interpolation='mitchell', vmin=0, vmax=70)\npl2.plot(peak_data['x'],peak_data['y'], 'r.', markersize=2)\nplt.tight_layout()\nplt.show()\n</pre> fig, [pl1, pl2] = plt.subplots(1, 2, figsize=(6, 4)) tomo_data_cpu = tomo_data.cpu() pl1.imshow(torch.min(tomo_data_cpu, dim=0).values, cmap='gray',interpolation='mitchell', vmin=0, vmax=70) pl2.imshow(torch.min(tomo_data_cpu, dim=0).values, cmap='gray',interpolation='mitchell', vmin=0, vmax=70) pl2.plot(peak_data['x'],peak_data['y'], 'r.', markersize=2) plt.tight_layout() plt.show() In\u00a0[9]: Copied! <pre>refined_peak_data = refine_peaks_3d(\n    volume = -1. * tomo_data + torch.randn_like(tomo_data,dtype=torch.float32) * 0.001,\n    peak_coords= peak_data,\n    return_as=\"dataframe\",\n    boxsize=10\n)\n</pre> refined_peak_data = refine_peaks_3d(     volume = -1. * tomo_data + torch.randn_like(tomo_data,dtype=torch.float32) * 0.001,     peak_coords= peak_data,     return_as=\"dataframe\",     boxsize=10 ) <pre>torch.Size([268, 7])\ntorch.Size([268, 7])\n</pre> In\u00a0[12]: Copied! <pre>plt.hist(refined_peak_data['amplitude'], bins=100)\npass\n</pre> plt.hist(refined_peak_data['amplitude'], bins=100) pass In\u00a0[13]: Copied! <pre>plt.hist(refined_peak_data['sigma_x'], bins=100)\npass\n</pre> plt.hist(refined_peak_data['sigma_x'], bins=100) pass In\u00a0[14]: Copied! <pre>plt.hist(refined_peak_data['sigma_y'], bins=100)\n</pre> plt.hist(refined_peak_data['sigma_y'], bins=100) Out[14]: <pre>(array([ 1.,  3.,  4.,  8., 13., 26., 14., 40., 55., 55., 22., 16.,  3.,\n         0.,  3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,\n         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n         0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n         0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  1.]),\n array([0.58873951, 0.64283109, 0.6969226 , 0.75101411, 0.80510569,\n        0.85919726, 0.91328877, 0.96738029, 1.02147186, 1.07556343,\n        1.12965488, 1.18374646, 1.23783803, 1.2919296 , 1.34602118,\n        1.40011263, 1.4542042 , 1.50829577, 1.56238723, 1.6164788 ,\n        1.67057037, 1.72466195, 1.7787534 , 1.83284497, 1.88693655,\n        1.94102812, 1.99511969, 2.04921103, 2.10330272, 2.15739441,\n        2.21148586, 2.26557732, 2.31966877, 2.37376046, 2.42785215,\n        2.48194361, 2.53603506, 2.59012651, 2.64421797, 2.6983099 ,\n        2.75240135, 2.80649281, 2.86058426, 2.91467571, 2.96876717,\n        3.0228591 , 3.07695055, 3.131042  , 3.18513346, 3.23922491,\n        3.29331684, 3.34740829, 3.40149975, 3.4555912 , 3.50968266,\n        3.56377459, 3.61786604, 3.67195749, 3.72604895, 3.7801404 ,\n        3.83423185, 3.88832378, 3.94241524, 3.99650669, 4.05059814,\n        4.1046896 , 4.15878153, 4.21287298, 4.26696444, 4.32105589,\n        4.37514734, 4.42923927, 4.48333073, 4.53742218, 4.59151363,\n        4.64560509, 4.69969654, 4.75378799, 4.80787992, 4.86197138,\n        4.91606283, 4.97015429, 5.02424574, 5.07833767, 5.13242912,\n        5.18652058, 5.24061203, 5.29470348, 5.34879494, 5.40288687,\n        5.45697832, 5.51106977, 5.56516123, 5.61925268, 5.67334461,\n        5.72743607, 5.78152752, 5.83561897, 5.88971043, 5.94380236,\n        5.99789381]),\n &lt;BarContainer object of 100 artists&gt;)</pre> In\u00a0[15]: Copied! <pre>plt.hist(refined_peak_data['sigma_z'], bins=100)\n</pre> plt.hist(refined_peak_data['sigma_z'], bins=100) Out[15]: <pre>(array([ 3.,  0.,  0.,  1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  1.,  1.,\n         4.,  0.,  1.,  1.,  0.,  2.,  2.,  4.,  3.,  0.,  5.,  5.,  0.,\n         1.,  3.,  2.,  2.,  1.,  2.,  1.,  5.,  1.,  5.,  2.,  2.,  7.,\n         7.,  3.,  6.,  5.,  5.,  8., 15., 11.,  4., 14.,  5., 13.,  7.,\n         9., 10.,  6.,  6.,  9.,  9.,  7.,  2.,  5.,  4.,  4.,  2.,  3.,\n         4.,  1.,  2.,  2.,  0.,  1.,  0.,  0.,  2.,  0.,  0.,  2.,  0.,\n         0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,\n         0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  1.]),\n array([1.17592347, 1.22458911, 1.27325475, 1.32192039, 1.37058604,\n        1.41925168, 1.46791732, 1.51658297, 1.56524861, 1.61391425,\n        1.66257989, 1.71124554, 1.75991106, 1.80857682, 1.85724235,\n        1.90590811, 1.95457363, 2.00323939, 2.05190492, 2.10057068,\n        2.1492362 , 2.19790173, 2.24656749, 2.29523325, 2.34389877,\n        2.3925643 , 2.44123006, 2.48989582, 2.53856134, 2.58722687,\n        2.63589263, 2.68455839, 2.73322392, 2.78188944, 2.8305552 ,\n        2.87922096, 2.92788649, 2.97655201, 3.02521777, 3.07388353,\n        3.12254906, 3.17121458, 3.2198801 , 3.2685461 , 3.31721163,\n        3.36587715, 3.41454268, 3.46320868, 3.5118742 , 3.56053972,\n        3.60920525, 3.65787125, 3.70653677, 3.75520229, 3.80386782,\n        3.85253382, 3.90119934, 3.94986486, 3.99853039, 4.04719639,\n        4.09586191, 4.14452744, 4.19319296, 4.24185896, 4.29052448,\n        4.33919001, 4.38785553, 4.43652105, 4.48518705, 4.53385258,\n        4.5825181 , 4.63118362, 4.67984962, 4.72851515, 4.77718067,\n        4.8258462 , 4.8745122 , 4.92317772, 4.97184324, 5.02050877,\n        5.06917477, 5.11784029, 5.16650581, 5.21517134, 5.26383686,\n        5.31250286, 5.36116838, 5.40983391, 5.45849943, 5.50716543,\n        5.55583096, 5.60449648, 5.653162  , 5.701828  , 5.75049353,\n        5.79915905, 5.84782457, 5.8964901 , 5.9451561 , 5.99382162,\n        6.04248714]),\n &lt;BarContainer object of 100 artists&gt;)</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/fit_2dtm_peaks/","title":"Fit 2dtm peaks","text":"In\u00a0[10]: Copied! <pre>import pooch\nimport mrcfile\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch_find_peaks.find_peaks import find_peaks_2d\nfrom torch_find_peaks.refine_peaks import refine_peaks_2d\n</pre> import pooch import mrcfile import matplotlib.pyplot as plt import torch from torch_find_peaks.find_peaks import find_peaks_2d from torch_find_peaks.refine_peaks import refine_peaks_2d In\u00a0[2]: Copied! <pre>mip = pooch.retrieve(\"https://ftp.ebi.ac.uk/empiar/world_availability/11544/data/scaled_mips/136_Sep13_10.27.07_231_1_scaled_mip_29_0.mrc\",known_hash=None)\n</pre> mip = pooch.retrieve(\"https://ftp.ebi.ac.uk/empiar/world_availability/11544/data/scaled_mips/136_Sep13_10.27.07_231_1_scaled_mip_29_0.mrc\",known_hash=None) In\u00a0[3]: Copied! <pre>with mrcfile.open(mip) as mrc:\n    mip_tensor = torch.tensor(mrc.data[0])\n</pre> with mrcfile.open(mip) as mrc:     mip_tensor = torch.tensor(mrc.data[0]) In\u00a0[4]: Copied! <pre>plt.imshow(mip_tensor, cmap='gray',interpolation='none',vmax=8.0,vmin=6.0)\n</pre> plt.imshow(mip_tensor, cmap='gray',interpolation='none',vmax=8.0,vmin=6.0) Out[4]: <pre>&lt;matplotlib.image.AxesImage at 0x7fe782b39690&gt;</pre> In\u00a0[62]: Copied! <pre>peak_data = find_peaks_2d(mip_tensor-float(mip_tensor.median()), \n                          threshold_abs=7.6-float(mip_tensor.median()), \n                          min_distance=5,\n                          return_as='dataframe')\n</pre> peak_data = find_peaks_2d(mip_tensor-float(mip_tensor.median()),                            threshold_abs=7.6-float(mip_tensor.median()),                            min_distance=5,                           return_as='dataframe') In\u00a0[63]: Copied! <pre>plt.hist(peak_data['height'], bins=20)\npass\n</pre> plt.hist(peak_data['height'], bins=20) pass In\u00a0[64]: Copied! <pre>refined_peaks = refine_peaks_2d(mip_tensor-mip_tensor.median(),\n                                peak_coords=peak_data,\n                                boxsize=6,\n                                learning_rate=0.1,\n                                sigma_x=1.5,\n                                sigma_y=1.5,\n                                return_as='dataframe')\n</pre> refined_peaks = refine_peaks_2d(mip_tensor-mip_tensor.median(),                                 peak_coords=peak_data,                                 boxsize=6,                                 learning_rate=0.1,                                 sigma_x=1.5,                                 sigma_y=1.5,                                 return_as='dataframe') In\u00a0[65]: Copied! <pre>plt.hist(refined_peaks['amplitude'].to_numpy()+float(mip_tensor.median()), bins=20)\n</pre> plt.hist(refined_peaks['amplitude'].to_numpy()+float(mip_tensor.median()), bins=20) Out[65]: <pre>(array([ 3., 13., 21., 27., 38., 40., 36., 32., 31., 31., 23.,  6., 12.,\n         4.,  4.,  3.,  3.,  1.,  1.,  1.]),\n array([ 7.25453329,  7.53774309,  7.82095337,  8.10416317,  8.38737297,\n         8.67058277,  8.95379257,  9.23700237,  9.52021217,  9.80342293,\n        10.08663273, 10.36984253, 10.65305233, 10.93626213, 11.21947193,\n        11.50268173, 11.78589249, 12.06910133, 12.35231209, 12.63552189,\n        12.91873169]),\n &lt;BarContainer object of 20 artists&gt;)</pre> In\u00a0[73]: Copied! <pre>plt.hist(refined_peaks['sigma_x'], bins=20)\npass\n</pre> plt.hist(refined_peaks['sigma_x'], bins=20) pass In\u00a0[70]: Copied! <pre>plt.hist(refined_peaks['sigma_y'], bins=20)\npass\n</pre> plt.hist(refined_peaks['sigma_y'], bins=20) pass In\u00a0[71]: Copied! <pre>plt.plot(refined_peaks['sigma_x'], refined_peaks['amplitude'].to_numpy()+float(mip_tensor.median()), 'ro', markersize=1)\npass\n</pre> plt.plot(refined_peaks['sigma_x'], refined_peaks['amplitude'].to_numpy()+float(mip_tensor.median()), 'ro', markersize=1) pass In\u00a0[72]: Copied! <pre>plt.plot(refined_peaks['sigma_x'], refined_peaks['sigma_y'], 'ro', markersize=1)\npass\n</pre> plt.plot(refined_peaks['sigma_x'], refined_peaks['sigma_y'], 'ro', markersize=1) pass In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"examples/plot_gaussians/","title":"Plot gaussians","text":"In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport torch\nfrom torch_grid_utils.coordinate_grid import coordinate_grid\n\nfrom torch_find_peaks.gaussians import Gaussian2D, WarpedGaussian2D\n\ng1 = Gaussian2D(1.,0., 0., 10., 5.)\n\ngrid = coordinate_grid((100,100), center=torch.tensor([50.,50.]))\n\nim_g1 = g1(grid)\n</pre> import matplotlib.pyplot as plt import torch from torch_grid_utils.coordinate_grid import coordinate_grid  from torch_find_peaks.gaussians import Gaussian2D, WarpedGaussian2D  g1 = Gaussian2D(1.,0., 0., 10., 5.)  grid = coordinate_grid((100,100), center=torch.tensor([50.,50.]))  im_g1 = g1(grid) In\u00a0[2]: Copied! <pre>plt.imshow(im_g1.detach().numpy(), cmap='gray')\n</pre> plt.imshow(im_g1.detach().numpy(), cmap='gray') Out[2]: <pre>&lt;matplotlib.image.AxesImage at 0x7f080132da60&gt;</pre> In\u00a0[6]: Copied! <pre>g2 = WarpedGaussian2D(1.,0.,0., 5.0, 5.0, 0.2, 0.)\n</pre> g2 = WarpedGaussian2D(1.,0.,0., 5.0, 5.0, 0.2, 0.) In\u00a0[7]: Copied! <pre>im_g2 = g2(grid)[0]\nplt.imshow(im_g2.detach().numpy(), cmap='gray')\n</pre> im_g2 = g2(grid)[0] plt.imshow(im_g2.detach().numpy(), cmap='gray') Out[7]: <pre>&lt;matplotlib.image.AxesImage at 0x7f2e51be4a10&gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"}]}